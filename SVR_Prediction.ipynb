{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "class SVR_model():\n",
    "    def __init__(self):\n",
    "        self.t_range=24\n",
    "        self.hour_after=24\n",
    "        self.data=[]\n",
    "        self.data_shuffle=[]\n",
    "        \n",
    "    def pca_estimator(self):\n",
    "\n",
    "    #本函数的主要功能设定主成分分析的系数并对数据进行主成分分析降维。\n",
    "    #:param self.data: 输入数据\n",
    "    #:return: 降维后的数据\n",
    "\n",
    "        estimator = PCA(n_components=25)\n",
    "        estimator.fit_transform(self.data)\n",
    "        return estimator\n",
    "    \n",
    "    def ml_train(self):\n",
    "\n",
    "    #利用机器学习方法训练数据\n",
    "    #:param self.t_range:\n",
    "    #:param self.hour_after: 预测间隔小时数\n",
    "    #:param self.data: 数据源\n",
    "    #:param target: 判断负荷预测/能耗预测\n",
    "    #:return: None\n",
    "\n",
    "        print('--ml model training start--'.format(a=target))\n",
    "        ml_method_list = ['svr']\n",
    "   \n",
    "        self.data_set = self.data.dropna(axis=1, how='all')\n",
    "        self.data_set = self.data_set.dropna()\n",
    "\n",
    "    # 划分训练集、验证集\n",
    "        self.data_shuffle = shuffle(self.data_set)  # （乱序方式）\n",
    "        train_test_point = int(self.data_shuffle.shape[0] * 0.80)\n",
    "        train_index = self.data_shuffle.index[0: train_test_point]\n",
    "        test_index = self.data_shuffle.index[train_test_point: -1]\n",
    "        train_self.data = self.data_shuffle.iloc[:train_test_point, :].values\n",
    "        test_self.data = self.data_shuffle.iloc[train_test_point:-1, :].values\n",
    "\n",
    "    \n",
    "    # Normalizing with pca decomposition\n",
    "        print('Normalizing with pca decomposition process starts at ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "        x_scaler = preprocessing.MinMaxScaler()\n",
    "        y_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "        train_x = x_scaler.fit_transform(train_self.data[:, 1:])\n",
    "        estimator = self.pca_estimator(train_x)\n",
    "        test_x = x_scaler.transform(test_self.data[:, 1:])\n",
    "        train_x = estimator.transform(train_x)\n",
    "        test_x = estimator.transform(test_x)\n",
    "\n",
    "        train_y = y_scaler.fit_transform(train_self.data[:, 0].reshape(-1, 1)).reshape(-1)\n",
    "        test_y = y_scaler.transform(test_self.data[:, 0].reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "                                       \n",
    "\n",
    "        fit_svr, pred_svr, svr_model = train_svr(train_x=train_x, train_y=train_y,\n",
    "                                             predict_x=test_x,\n",
    "                                             svr_kernel='rbf',\n",
    "                                             )\n",
    "\n",
    "    \n",
    "        ml_model_list = [svr_model]\n",
    "        fit_norm_list = [fit_svr]\n",
    "        pred_norm_list = [pred_svr]\n",
    "\n",
    "        fit_list = []\n",
    "        pred_list = []\n",
    "\n",
    "    # 将数据从（0,1）还原至真实值\n",
    "        for fit in fit_norm_list:\n",
    "            fit_list.append(y_scaler.inverse_transform(fit.reshape(-1, 1)))\n",
    "        for pred in pred_norm_list:\n",
    "            pred_list.append(y_scaler.inverse_transform(pred.reshape(-1, 1)))\n",
    "\n",
    "        train_y = y_scaler.inverse_transform(train_y.reshape(-1, 1))\n",
    "        test_y = y_scaler.inverse_transform(test_y.reshape(-1, 1))\n",
    "\n",
    "        # print(validation_f2(test_y, pred_list[0]))\n",
    "\n",
    "    # 画图\n",
    "        plt.figure(num='ml_test')\n",
    "        plt.title(self.data_set.columns[0])\n",
    "        line_list = [test_y.tolist(), ]\n",
    "        line_name_list = ['actual', ]\n",
    "        for i in range(len(ml_method_list)):\n",
    "            line_list.append(plt.plot(pred_list[i]))\n",
    "            line_name_list.append(\"pred\" + ml_method_list[i])\n",
    "        plt.legend(line_name_list, loc='upper right')\n",
    "        plt.plot(test_y.reshape(-1))\n",
    "        plt.plot(pred_list[0])\n",
    "        plt.legend(['actual', 'svr'])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # 数据后处理待学习\n",
    "        return None\n",
    "    \n",
    "    def train_svr(self,train_x, train_y, predict_x, svr_kernel):\n",
    "\n",
    "    #本函数用于训练SVR模型，并通过网格搜索确定模型最佳的C，gamma和ε。\n",
    "    #:param train_x: 训练集输入\n",
    "    #:param train_y: 训练目标值\n",
    "    #:param predict_x: 验证集输入\n",
    "    #:param svr_kernel: SVR核函数选择\n",
    "    #:return: 返回模型，预测值，模型拟合值\n",
    "\n",
    "        c_range = np.array([0.1, 0.5, 1, 2, 3, 4, 5, 10, 50, 100, 500, 1000])\n",
    "        gamma_range = np.array([0.001, 0.01, 0.05,\n",
    "                            0.1, 0.5, 1, 5, 10, 50, 100])\n",
    "        epsilon_range = np.array([0.001, 0.01, 0.1, 1])\n",
    "        param_grid = dict(gamma=gamma_range, C=c_range, epsilon=epsilon_range)\n",
    "        # use the grid search to go through all the cases\n",
    "        grid = GridSearchCV(SVR(kernel=svr_kernel), scoring='neg_mean_absolute_error', n_jobs=-1,\n",
    "                            param_grid=param_grid, cv=5)\n",
    "        grid.fit(train_x, train_y)\n",
    "        # set the parameters of svr\n",
    "        svr = grid.best_estimator_\n",
    "        # svr = SVR(kernel=svr_kernel, degree=3, gamma=svr_gamma, coef0=0.0, tol=0.001, C=svr_c,\n",
    "        #           epsilon=svr_epsilon, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "        # command to fit the train self.data set\n",
    "        svr.fit(train_x, train_y)\n",
    "        # result of fitting and prediction\n",
    "        svr_fit = svr.predict(train_x)\n",
    "        svr_pred = svr.predict(predict_x)\n",
    "\n",
    "        return [svr_fit, svr_pred, svr]\n",
    "    \n",
    "    def pred_svr(x_np, y_scaler, svr_model):\n",
    "        y = svr_model.predict(x_np)\n",
    "        pred_value = y_scaler.inverse_transform(y.reshape(-1, 1))\n",
    "        # print('svr prediction done')\n",
    "        return pred_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
